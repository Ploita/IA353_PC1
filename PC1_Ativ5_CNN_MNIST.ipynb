{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xMsNyA3WPrER"
      },
      "source": [
        "## **Notebook PC1_Ativ5**\n",
        "## Convolutional classifier for the MNIST database.\n",
        "**Professor:** Fernando J. Von Zuben <br>\n",
        "**Aluno(a):** Arthur Felipe dos Santos Fernandes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzk_w5ftc4bi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape to be [samples][width][height][channels]\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
        "                                 activation='relu',\n",
        "                                 input_shape=(28, 28, 1)))\n",
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "model.summary()\n",
        "# Evaluate the model on the test data using `evaluate`\n",
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(x_test, y_test)\n",
        "print(\"test loss, test acc:\", results)\n",
        "model_json = model.to_json()\n",
        "json_file = open(\"model_CNN.json\", \"w\")\n",
        "json_file.write(model_json)\n",
        "json_file.close()\n",
        "model.save_weights(\"model_CNN.h5\")\n",
        "print(\"Model saved to disk\")\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "Number of devices: 1\n",
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2282 - sparse_categorical_accuracy: 0.9316 - val_loss: 0.1260 - val_sparse_categorical_accuracy: 0.9617\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0968 - sparse_categorical_accuracy: 0.9710 - val_loss: 0.0917 - val_sparse_categorical_accuracy: 0.9725\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0615 - sparse_categorical_accuracy: 0.9811 - val_loss: 0.0984 - val_sparse_categorical_accuracy: 0.9721\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0443 - sparse_categorical_accuracy: 0.9863 - val_loss: 0.0947 - val_sparse_categorical_accuracy: 0.9747\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0359 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.0975 - val_sparse_categorical_accuracy: 0.9765\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0297 - sparse_categorical_accuracy: 0.9898 - val_loss: 0.1141 - val_sparse_categorical_accuracy: 0.9734\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0237 - sparse_categorical_accuracy: 0.9923 - val_loss: 0.1085 - val_sparse_categorical_accuracy: 0.9756\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0230 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.1061 - val_sparse_categorical_accuracy: 0.9778\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0175 - sparse_categorical_accuracy: 0.9942 - val_loss: 0.1097 - val_sparse_categorical_accuracy: 0.9777\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0211 - sparse_categorical_accuracy: 0.9931 - val_loss: 0.1236 - val_sparse_categorical_accuracy: 0.9766\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0164 - sparse_categorical_accuracy: 0.9945 - val_loss: 0.1198 - val_sparse_categorical_accuracy: 0.9782\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0138 - sparse_categorical_accuracy: 0.9954 - val_loss: 0.1263 - val_sparse_categorical_accuracy: 0.9776\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0164 - sparse_categorical_accuracy: 0.9951 - val_loss: 0.1452 - val_sparse_categorical_accuracy: 0.9755\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0143 - sparse_categorical_accuracy: 0.9954 - val_loss: 0.1272 - val_sparse_categorical_accuracy: 0.9803\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0131 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.1589 - val_sparse_categorical_accuracy: 0.9744\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0114 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.1553 - val_sparse_categorical_accuracy: 0.9774\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0158 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.1462 - val_sparse_categorical_accuracy: 0.9803\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0111 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.1456 - val_sparse_categorical_accuracy: 0.9787\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0132 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.1801 - val_sparse_categorical_accuracy: 0.9726\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0102 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.1493 - val_sparse_categorical_accuracy: 0.9775\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 0.1382 - sparse_categorical_accuracy: 0.9775\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.1381690800189972, 0.9775000214576721]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import keras\n",
        "def get_compiled_model():\n",
        "    # Make a simple 2-layer densely-connected neural network.\n",
        "    inputs = keras.Input(shape=(784,))\n",
        "    x = keras.layers.Dense(256, activation=\"relu\")(inputs)\n",
        "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "    outputs = keras.layers.Dense(10)(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_dataset():\n",
        "    batch_size = 32\n",
        "    num_val_samples = 10000\n",
        "\n",
        "    # Return the MNIST dataset in the form of a [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset).\n",
        "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "    # Preprocess the data (these are Numpy arrays)\n",
        "    x_train = x_train.reshape(-1, 784).astype(\"float32\") / 255\n",
        "    x_test = x_test.reshape(-1, 784).astype(\"float32\") / 255\n",
        "    y_train = y_train.astype(\"float32\")\n",
        "    y_test = y_test.astype(\"float32\")\n",
        "\n",
        "    # Reserve num_val_samples samples for validation\n",
        "    x_val = x_train[-num_val_samples:]\n",
        "    y_val = y_train[-num_val_samples:]\n",
        "    x_train = x_train[:-num_val_samples]\n",
        "    y_train = y_train[:-num_val_samples]\n",
        "    return (\n",
        "        tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size),\n",
        "        tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size),\n",
        "        tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size),\n",
        "    )\n",
        "\n",
        "\n",
        "# Create a MirroredStrategy.\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
        "\n",
        "# Open a strategy scope.\n",
        "with strategy.scope():\n",
        "    # Everything that creates variables should be under the strategy scope.\n",
        "    # In general this is only model construction & `compile()`.\n",
        "    model = get_compiled_model()\n",
        "\n",
        "# Train the model on all available devices.\n",
        "train_dataset, val_dataset, test_dataset = get_dataset()\n",
        "model.fit(train_dataset, epochs=2, validation_data=val_dataset)\n",
        "\n",
        "# Test the model on all available devices.\n",
        "model.evaluate(test_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Modelos  Acurácia\n",
            "0      LC    0.8642\n",
            "1     ELM    0.9413\n",
            "2     MLP    0.9778\n",
            "3     CNN    0.9775\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crie uma lista com os nomes dos modelos\n",
        "modelos = [ 'LC', 'ELM', 'MLP', 'CNN']\n",
        "\n",
        "# Crie uma lista com as acurácias dos modelos\n",
        "acuracias = [0.8642,\n",
        "             0.9413,\n",
        "             0.9778,\n",
        "             0.9775\n",
        "]\n",
        "\n",
        "# Crie um dataframe do pandas com as informações\n",
        "df = pd.DataFrame({'Modelos': modelos, 'Acurácia': acuracias})\n",
        "\n",
        "# Imprima a tabela\n",
        "print(df)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
